## Federated Distillation

This repository contains TensorFlow codes to simulate Federated Distillation using a partitioned version of Cifar10 dataset.
The implementations are based on the papers: [Distillation-Based Semi-Supervised Federated Learning for Communication-Efficient Collaborative Training with Non-IID Private Data
](https://arxiv.org/abs/2008.06180) and [CFD: Communication-Efficient Federated Distillation via Soft-Label Quantization and Delta
Coding](https://ieeexplore.ieee.org/abstract/document/9435947).


### Data partitioning

The CIFAR10 dataset is partitioned following the paper [Measuring the Effects of Non-Identical Data
Distribution for Federated Visual Classification](https://arxiv.org/abs/1909.06335): a Dirichlet distribution is used to decide the per-client label distribution. 
A concentration parameter controls the identicalness among clients. Very high values for such a concentration parameter, `alpha` in the code, (e.g., > 100.0) imply an identical distribution of labels among clients,
while low (e.g., 1.0) values produce a very different amount of examples for each label in clients, and for very low values (e.g., 0.1) all the client's examples belong to a single class.

### Instructions
`simulation.py` contains the Federated Distillation simulation. Hyperparameters can be choosen by manually modifying the
`hp` dictionary. A simulation of each combination of hyperparameters will be run.

Note: before running the simulation(s) the `partitioned cifar10` must be created using the provided script (see the following).

#### Creating a virtual environment with venv
`python3 -m venv fd_env`

`source fd_env/bin/activate`

`pip install -r requirements.txt`

The code has been tested with `python==3.8.10`.

#### Creating a virtual environment with venv
Running the simulation(s).

`python3 simulation.py`

#### Creating partitioned CIFAR10   
Before running `simulation.py`, the partitioned CIFAR10 dataset must be generated by executing `partition_cifar10.py`. 
The script will create a `cifar10_datasets_sattler_alpha` folder inside the current directory. This directory will 
contain a folder for each `client` with their examples.

If possible, the `partition_cifar10.py` will create disjoint dataset for clients.

### Useful information

The script `create_stl10_dataset.py` will save on disk a number of differently shuffled versions of preprocessed stl10.
This may be useful to speed up simulation at the cost of disk space. At default, the `simulation.py` preprocesses (e.g.,
resize images) and shuffles the data examples on the fly. 

#### Logging

The `simulation.py` produces logging txt files with per-round metrics. It creates a `simulation` folder to contain the log files.

### Datasets
Here a list of datasets used throughout the code.
- [cifar10](https://www.tensorflow.org/datasets/catalog/cifar10)
